{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with organizations locations and persons with worksAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:32:21.045838Z",
     "iopub.status.busy": "2024-05-08T09:32:21.045557Z",
     "iopub.status.idle": "2024-05-08T09:33:20.071313Z",
     "shell.execute_reply": "2024-05-08T09:33:20.070299Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV , train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from kge.util.io import load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load entities and their embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:20.075491Z",
     "iopub.status.busy": "2024-05-08T09:33:20.075037Z",
     "iopub.status.idle": "2024-05-08T09:33:20.490650Z",
     "shell.execute_reply": "2024-05-08T09:33:20.489858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n"
     ]
    }
   ],
   "source": [
    "PATH_EMBED = '../embeddings/'\n",
    "\n",
    "# Load entity type Dataframe\n",
    "entities_df = pd.read_csv('data/entities_types.csv', sep=',', header=0)\n",
    "\n",
    "#load YAGO Embeddings\n",
    "checkpoint = load_checkpoint(PATH_EMBED + 'yago3-10-complex.pt') # Change the model here\n",
    "model = checkpoint[\"model\"]\n",
    "tensor_embed: torch.Tensor = dict(checkpoint['model'][0])['_entity_embedder._embeddings.weight']\n",
    "all_arrays = tensor_embed.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:20.573385Z",
     "iopub.status.busy": "2024-05-08T09:33:20.572800Z",
     "iopub.status.idle": "2024-05-08T09:33:21.447057Z",
     "shell.execute_reply": "2024-05-08T09:33:21.446232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading triples...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset to get the relations\n",
    "print(\"Loading triples...\")\n",
    "GLOBAL_PATH = \"data/\"\n",
    "NAME_SUBGRAPH = [\"train\", \"test\", \"valid\"]\n",
    "cols_name = [\"head\", \"relation\", \"tail\"]\n",
    "triples_df = pd.concat(\n",
    "    (pd.read_csv(\n",
    "        GLOBAL_PATH + f + '.txt',\n",
    "        sep=\"\\t\",\n",
    "        names=cols_name) for f in NAME_SUBGRAPH),\n",
    "    ignore_index=True)\n",
    "# Get distinct relations\n",
    "distinct_relations = triples_df[\"relation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:21.449995Z",
     "iopub.status.busy": "2024-05-08T09:33:21.449852Z",
     "iopub.status.idle": "2024-05-08T09:33:54.351859Z",
     "shell.execute_reply": "2024-05-08T09:33:54.350815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the relations exists...\n"
     ]
    }
   ],
   "source": [
    "# Dictionnary for all the boolean value of relation regarding entitiy\n",
    "value_relations = {relation: set() for relation in distinct_relations}\n",
    "\n",
    "print(\"Check if the relations exists...\")\n",
    "for _, row in triples_df.iterrows():\n",
    "    # Extract entity and relations\n",
    "    head = row[\"head\"]\n",
    "    relation = row[\"relation\"]\n",
    "    # Add the entity to the corresponding set\n",
    "    value_relations[relation].add(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:54.355276Z",
     "iopub.status.busy": "2024-05-08T09:33:54.355110Z",
     "iopub.status.idle": "2024-05-08T09:33:55.005108Z",
     "shell.execute_reply": "2024-05-08T09:33:55.004330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a global DataFrame with all the data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate a global DataFrame with all the data...\")\n",
    "# Convert the sets into a boolean lists\n",
    "value_relations = {relation: [entity in value_relations[relation]\n",
    "                              for entity in entities_df[\"Entity\"]] for relation in distinct_relations}\n",
    "# Convert to a Pandas Dataframe\n",
    "relations_df = pd.DataFrame(value_relations)\n",
    "global_df = pd.concat((entities_df, relations_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:55.007980Z",
     "iopub.status.busy": "2024-05-08T09:33:55.007843Z",
     "iopub.status.idle": "2024-05-08T09:33:55.021139Z",
     "shell.execute_reply": "2024-05-08T09:33:55.020451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe city to continent\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataframe city to continent\")\n",
    "# Load the Dataframe of city to continent\n",
    "city_continent_df = pd.read_csv(\"data/city_global_location.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:55.023828Z",
     "iopub.status.busy": "2024-05-08T09:33:55.023696Z",
     "iopub.status.idle": "2024-05-08T09:33:55.026681Z",
     "shell.execute_reply": "2024-05-08T09:33:55.026132Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining parameter range ofr GridSearch\n",
    "# Define the hyperparameter grid\n",
    "param_grid = [\n",
    "  {'C': [0.1, 1, 2.5, 5, 7.5, 10], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T09:33:55.029756Z",
     "iopub.status.busy": "2024-05-08T09:33:55.029556Z",
     "iopub.status.idle": "2024-05-08T09:33:55.049531Z",
     "shell.execute_reply": "2024-05-08T09:33:55.048787Z"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_score(ref, neighbours, df_with_labels, mode: str = \"one\"):\n",
    "    # Determine the label of the reference\n",
    "    label_ref = df_with_labels[df_with_labels['Entity']== ref]['labels'].to_list()[0]\n",
    "    \n",
    "    # Determine labels for all neighbors at once\n",
    "    all_neighbours_labels = np.array([df_with_labels[df_with_labels['Entity'] == name]['labels'].to_list()[0] for name in neighbours])\n",
    "\n",
    "    # Calculate intersection scores\n",
    "\n",
    "    if mode == \"one\":\n",
    "        intersect_labels = np.logical_and(label_ref, all_neighbours_labels)\n",
    "        # Sum the intersect labels along axis 1 (columns) and count non-zero elements\n",
    "        non_zero = np.count_nonzero(intersect_labels, axis=1)\n",
    "\n",
    "        # Count number of rows with non-zero elements\n",
    "        score = np.count_nonzero(non_zero)\n",
    "    elif mode == \"all\":\n",
    "        all_each_line = np.all(all_neighbours_labels == label_ref, axis=1)\n",
    "        # Count number of rows with non-zero elements\n",
    "        score = np.count_nonzero(all_each_line)\n",
    "    else:\n",
    "        raise ValueError(\"This is not a valid mode.\")\n",
    "\n",
    "    return score / len(neighbours)\n",
    "\n",
    "def closest_neighbours(ref_entity, other_entities, df_with_labels, k, mode: str = \"euclidean\"):\n",
    "    if mode == \"euclidean\":\n",
    "        relative_ref = other_entities - ref_entity\n",
    "        dist_to_ref = np.linalg.norm(relative_ref, axis=1)\n",
    "        k_closest_entity = np.argsort(dist_to_ref)[1:(k+1)]\n",
    "        return df_with_labels['Entity'].iloc[k_closest_entity]\n",
    "    elif mode == \"cosine\":\n",
    "        norm_ref = np.linalg.norm(ref_entity)\n",
    "        ref_norm = ref_entity / norm_ref\n",
    "        norm_other = np.linalg.norm(other_entities, axis=1)\n",
    "        normalized_other = np.divide(other_entities, norm_other.reshape(-1,1)) # division elementwise\n",
    "        cosine_sim = normalized_other.dot(ref_norm.T).reshape(-1,)\n",
    "        # We take the k elemnt with the highest score\n",
    "        k_closest_values = np.argsort(cosine_sim)[-(k+1):-1]\n",
    "        return df_with_labels['Entity'].iloc[k_closest_values]\n",
    "    raise ValueError(\"This is not a valid mode of similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads all the data related to humans\n",
    "entity_type = \"organization_108008335\"\n",
    "\n",
    "triples_organization_location = triples_df[(triples_df['relation'] == 'isLocatedIn')]\n",
    "organization_head = set(triples_organization_location['head'].to_list())\n",
    "\n",
    "\n",
    "organization_head = entities_df[entities_df['Entity'].isin(organization_head) & entities_df[\"type\"].apply(lambda x: entity_type in x)]\n",
    "organization_index = np.array(organization_head.index, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_locations = dict(city_continent_df[[\"cities\",\"countries\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale embeddings only to concerned data\n",
    "scale_organization_data = deepcopy(all_arrays)\n",
    "scale = StandardScaler()\n",
    "scale_organization_data[organization_index] = scale.fit_transform(scale_organization_data[organization_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_locations = [\"United States\", \"United Kingdom\", \"Canada\", \"Japan\", \"France\"]\n",
    "SVC_organization: list[GridSearchCV] = [GridSearchCV(SVC(class_weight='balanced'), param_grid, refit = True, verbose = 1, scoring = make_scorer(cohen_kappa_score), n_jobs=-1)]*len(top_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:27<00:00, 17.59s/it]\n"
     ]
    }
   ],
   "source": [
    "def isInCountry(location, country_ref):\n",
    "    if location in dict_locations.keys():\n",
    "        country = dict_locations[location]\n",
    "        return country == country_ref\n",
    "    return False\n",
    "\n",
    "labels_organization = [np.array([isInCountry(triples_organization_location[triples_organization_location['head'] == organization]['tail'].to_list()[0], location) for organization in entities_df['Entity'][organization_index]]) for location in tqdm(top_locations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 78.19 %\n",
      "The testing accuracy is: 43.37 %\n",
      "The testing kappa score is 0.43\n",
      "The best parameters are {'C': 1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 87.68 %\n",
      "The testing accuracy is: 58.43 %\n",
      "The testing kappa score is 0.58\n",
      "The best parameters are {'C': 1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 73.40 %\n",
      "The testing accuracy is: 46.93 %\n",
      "The testing kappa score is 0.47\n",
      "The best parameters are {'C': 0.1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 86.35 %\n",
      "The testing accuracy is: 60.18 %\n",
      "The testing kappa score is 0.60\n",
      "The best parameters are {'C': 1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 80.28 %\n",
      "The testing accuracy is: 61.77 %\n",
      "The testing kappa score is 0.62\n",
      "The best parameters are {'C': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "decision_organization = []\n",
    "for idx, svm in enumerate(SVC_organization):\n",
    "    # We split the entities\n",
    "    X_organization_train, X_organization_test, y_organization_train, y_organization_test  = train_test_split(scale_organization_data[organization_index], labels_organization[idx], test_size=0.2, random_state=42)\n",
    "    svm.fit(X_organization_train, y_organization_train)\n",
    "    print(\"The training accuracy is: {:.2f} %\".format(svm.score(X_organization_train, y_organization_train)*100))\n",
    "    print(\"The testing accuracy is: {:.2f} %\".format(svm.score(X_organization_test, y_organization_test)*100))\n",
    "    print(\"The testing kappa score is {:.2f}\".format(cohen_kappa_score(svm.predict(X_organization_test), y_organization_test)))\n",
    "    print(\"The best parameters are\", svm.best_params_)\n",
    "    decision_organization.append(svm.best_estimator_.decision_function(scale_organization_data).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting into the new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project and add bias through decision function\n",
    "organization_proj = np.concatenate(decision_organization, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1412/548220679.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  organization_head[\"labels\"] = labels_organization.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with all labels\n",
    "labels_organization = np.array(labels_organization).T\n",
    "organization_head[\"labels\"] = labels_organization.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbourhood similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2773/2773 [00:41<00:00, 66.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Global similarity score\n",
    "k=10\n",
    "scores_raw = 0\n",
    "scores_proj = 0\n",
    "for idx in tqdm(organization_index):\n",
    "    # Choose a ref\n",
    "    ref_proj = organization_proj[idx,:]\n",
    "    ref_name = organization_head['Entity'][idx]\n",
    "    # Before projection\n",
    "    ref_entity = scale_organization_data[idx,:]\n",
    "    closest_entity_raw = closest_neighbours(ref_entity, scale_organization_data[organization_index], organization_head, k)\n",
    "    scores_raw += similarity_score(ref_name, closest_entity_raw, organization_head, mode=\"all\")\n",
    "\n",
    "    # After projection\n",
    "    closest_entity = closest_neighbours(ref_proj, organization_proj[organization_index], organization_head, k)\n",
    "    scores_proj += similarity_score(ref_name, closest_entity, organization_head, mode=\"all\")\n",
    "\n",
    "scores_raw /= len(organization_index)\n",
    "scores_proj /= len(organization_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score before projection of the top10 entity is: 0.703\n",
      "The similarity score after projection of the top10 entity is: 0.897\n"
     ]
    }
   ],
   "source": [
    "print(f\"The similarity score before projection of the top{k} entity is: {round(scores_raw,3)}\")\n",
    "print(f\"The similarity score after projection of the top{k} entity is: {round(scores_proj,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WorksAt + type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads all the data related to humans\n",
    "entity_type = \"person_100007846\"\n",
    "\n",
    "triples_worksat = triples_df[(triples_df['relation'] == 'worksAt')]\n",
    "worksat_head = set(triples_worksat['head'].to_list())\n",
    "\n",
    "\n",
    "worksat_head = entities_df[entities_df['Entity'].isin(worksat_head) & entities_df[\"type\"].apply(lambda x: entity_type in x)]\n",
    "worksat_index = np.array(worksat_head.index, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_type = dict(entities_df[[\"Entity\", \"type\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale embeddings only to concerned data\n",
    "scale_worksat_data = deepcopy(all_arrays)\n",
    "scale = StandardScaler()\n",
    "scale_worksat_data[worksat_index] = scale.fit_transform(scale_worksat_data[worksat_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_work = [\"university_108286569\", \"educational_institution_108276342\", \"organization_108008335\"]\n",
    "SVC_worksat: list[GridSearchCV] = [GridSearchCV(SVC(class_weight='balanced'), param_grid, refit = True, verbose = 1, scoring = make_scorer(cohen_kappa_score), n_jobs=-1)]*len(top_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def isWork(work_type, work_ref):\n",
    "    if work_type in dict_type.keys():\n",
    "        work: list[str] = dict_type[work_type]\n",
    "        return work_ref in work\n",
    "    return False\n",
    "\n",
    "labels_worksat = [np.array([isWork(triples_worksat[triples_worksat['head'] == person]['tail'].to_list()[0], work) for person in entities_df['Entity'][worksat_index]]) for work in tqdm(top_work)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 59.75 %\n",
      "The testing accuracy is: 20.57 %\n",
      "The testing kappa score is 0.21\n",
      "The best parameters are {'C': 0.1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 92.82 %\n",
      "The testing accuracy is: 38.63 %\n",
      "The testing kappa score is 0.39\n",
      "The best parameters are {'C': 1, 'kernel': 'rbf'}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "The training accuracy is: 90.76 %\n",
      "The testing accuracy is: 30.70 %\n",
      "The testing kappa score is 0.31\n",
      "The best parameters are {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "decision_worksat = []\n",
    "for idx, svm in enumerate(SVC_worksat):\n",
    "    # We split the entities\n",
    "    X_worksat_train, X_worksat_test, y_worksat_train, y_worksat_test  = train_test_split(scale_worksat_data[worksat_index], labels_worksat[idx], test_size=0.2, random_state=42)\n",
    "    svm.fit(X_worksat_train, y_worksat_train)\n",
    "    print(\"The training accuracy is: {:.2f} %\".format(svm.score(X_worksat_train, y_worksat_train)*100))\n",
    "    print(\"The testing accuracy is: {:.2f} %\".format(svm.score(X_worksat_test, y_worksat_test)*100))\n",
    "    print(\"The testing kappa score is {:.2f}\".format(cohen_kappa_score(svm.predict(X_worksat_test), y_worksat_test)))\n",
    "    print(\"The best parameters are\", svm.best_params_)\n",
    "    decision_worksat.append(svm.best_estimator_.decision_function(scale_worksat_data).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting into the new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project and add bias through decision function\n",
    "worksat_proj = np.concatenate(decision_worksat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1412/1415401667.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  worksat_head[\"labels\"] = labels_worksat.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with all labels\n",
    "labels_worksat = np.array(labels_worksat).T\n",
    "worksat_head[\"labels\"] = labels_worksat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbourhood similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1376/1376 [00:14<00:00, 91.85it/s] \n"
     ]
    }
   ],
   "source": [
    "# Global similarity score\n",
    "k=10\n",
    "scores_raw = 0\n",
    "scores_proj = 0\n",
    "for idx in tqdm(worksat_index):\n",
    "    # Choose a ref\n",
    "    ref_proj = worksat_proj[idx,:]\n",
    "    ref_name = worksat_head['Entity'][idx]\n",
    "    # Before projection\n",
    "    ref_entity = scale_worksat_data[idx,:]\n",
    "    closest_entity_raw = closest_neighbours(ref_entity, scale_worksat_data[worksat_index], worksat_head, k)\n",
    "    scores_raw += similarity_score(ref_name, closest_entity_raw, worksat_head, mode=\"all\")\n",
    "\n",
    "    # After projection\n",
    "    closest_entity = closest_neighbours(ref_proj, worksat_proj[worksat_index], worksat_head, k)\n",
    "    scores_proj += similarity_score(ref_name, closest_entity, worksat_head, mode=\"all\")\n",
    "\n",
    "scores_raw /= len(worksat_index)\n",
    "scores_proj /= len(worksat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score before projection of the top10 entity is: 0.465\n",
      "The similarity score after projection of the top10 entity is: 0.807\n"
     ]
    }
   ],
   "source": [
    "print(f\"The similarity score before projection of the top{k} entity is: {round(scores_raw,3)}\")\n",
    "print(f\"The similarity score after projection of the top{k} entity is: {round(scores_proj,3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
